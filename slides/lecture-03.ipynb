{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Use seaborn for plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from IPython.html.widgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bias-Variance Tradeoff\n",
    "\n",
    "Let us work with a 1-D problem to  help us to easily visualize the data and the model. These results generalize easily to higher-dimensional datasets. Let us start by creating a  simple nonlinear function that we'd like to fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_func(x, err=0.5):\n",
    "    y = 10 - 1. / (x + 0.1)\n",
    "    if err > 0:\n",
    "        y = np.random.normal(y, err)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a function that samples `N` data points from this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_data(N=40, error=1.0, random_seed=1):\n",
    "    np.random.seed(random_seed)\n",
    "    X = np.random.random(N)[:, np.newaxis]\n",
    "    y = test_func(X.ravel(), error)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us create one dataset and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = make_data(40, error=1)\n",
    "plt.scatter(X.ravel(), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a built-in linear regression function to compute the simplest linear fit to this data and then plot the predictions on some `X_test` sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = np.linspace(-0.1, 1.1, 500)[:, None]\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_test = model.predict(X_test)\n",
    "\n",
    "plt.ylim([-2,14])\n",
    "plt.scatter(X.ravel(), y)\n",
    "plt.plot(X_test.ravel(), y_test, lw=3)\n",
    "plt.title(\"mean squared error: {0:.3g}\".format(metrics.mean_squared_error(model.predict(X), y)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us resample and fit this linear model a few times to see the variance of our predicted function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_mse = 0.0\n",
    "n_samples = 40\n",
    "n_sims = 20\n",
    "\n",
    "for i in range(n_sims):\n",
    "    X, y = make_data(n_samples, error=1, random_seed=i)\n",
    "    model.fit(X, y)\n",
    "    y_test = model.predict(X_test)\n",
    "    \n",
    "    plt.ylim([-2,14])\n",
    "    plt.scatter(X.ravel(), y, alpha=0.2)\n",
    "    plt.plot(X_test.ravel(), y_test, alpha=0.4, lw=3)\n",
    "    average_mse += metrics.mean_squared_error(model.predict(X), y)\n",
    "\n",
    "plt.title(\"average mean squared error: {0:.3g}\".format(average_mse/n_sims));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly this model is not a good choice. We say that this model is biased, or that it under-fits the data, however the variance of our estimates is quite small, since most of the estimates lie close to each other.\n",
    "\n",
    "Let's try to improve our model by  creating a more complicated model. We can do this by adding degrees of freedom, and computing a polynomial regression over the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree),\n",
    "                         linear_model.LinearRegression(**kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use this to fit a quadratic curve to the data repeatedly and compute the average of the errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = PolynomialRegression(degree=2)\n",
    "\n",
    "average_mse = 0.0\n",
    "n_samples = 40\n",
    "n_sims = 20\n",
    "\n",
    "for i in range(n_sims):\n",
    "    X, y = make_data(n_samples, error=1, random_seed=i)\n",
    "    model.fit(X, y)\n",
    "    y_test = model.predict(X_test)\n",
    "    \n",
    "    plt.ylim([-2,14])\n",
    "    plt.scatter(X.ravel(), y, alpha=0.2)\n",
    "    plt.plot(X_test.ravel(), y_test, alpha=0.4, lw=3)\n",
    "    average_mse += metrics.mean_squared_error(model.predict(X), y)\n",
    "    \n",
    "plt.title(\"average mean squared error: {0:.3g}\".format(average_mse/n_sims));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see we have reduced the mean square error and this model fits the data well. Perhaps we should just increase the complexity of our model, would that be better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = PolynomialRegression(degree=10)\n",
    "\n",
    "average_mse = 0.0\n",
    "n_samples = 40\n",
    "n_sims = 20\n",
    "\n",
    "for i in range(n_sims):\n",
    "    X, y = make_data(n_samples, error=1, random_seed=i)\n",
    "    model.fit(X, y)\n",
    "    y_test = model.predict(X_test)\n",
    "    \n",
    "    plt.ylim([-2,14])\n",
    "    plt.scatter(X.ravel(), y, alpha=0.2)\n",
    "    plt.plot(X_test.ravel(), y_test, alpha=0.4, lw=3)\n",
    "    average_mse += metrics.mean_squared_error(model.predict(X), y)\n",
    "    \n",
    "plt.title(\"average mean squared error: {0:.3g}\".format(average_mse/n_sims));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we increase the degree to this extent, it's clear that the resulting fit is no longer reflecting the true underlying distribution, and is more sensitive to the noise in the training data. We are at a situation called over-fitting, where the bias is very low but the variance of our estimators is very high.\n",
    "\n",
    "Just for fun, let's use IPython's interact capability to explore this interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_fit(degree=1, Npts=50):\n",
    "    X, y = make_data(Npts, error=1)\n",
    "    X_test = np.linspace(-0.1, 1.1, 500)[:, None]\n",
    "    \n",
    "    model = PolynomialRegression(degree=degree)\n",
    "    model.fit(X, y)\n",
    "    y_test = model.predict(X_test)\n",
    "\n",
    "    plt.scatter(X.ravel(), y)\n",
    "    plt.plot(X_test.ravel(), y_test)\n",
    "    plt.ylim(-4, 14)\n",
    "    plt.title(\"mean squared error: {0:.2f}\".format(metrics.mean_squared_error(model.predict(X), y)))\n",
    "    \n",
    "interact(plot_fit, degree=[1, 30], Npts=[2, 100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effects of `n_samples`\n",
    "\n",
    "Now let us investigate the effect of increasing and reducing the sample size (or size of our training data set) for these different situation of under-fitting, to optimal fitting and then overfitting.\n",
    "\n",
    "For the case with high bias, let us think what will happen. Increasing the number of points will lead to more or less the same straigh line. So plotting the error on data the algorithm has not seen, the error will plateau out after a certain number of data points. The same with the training error. It will start small and will end up close to the test error. So the learning curves will look like below, with high values of the error. So increasing the training data size will not by itself help:\n",
    "\n",
    "![](../data/lc-hb.png)\n",
    "\n",
    "Whereas if our algorithm is suffering from high variance, then getting more training data is likely to help:\n",
    "\n",
    "![](../data/lc-hv.png)\n",
    "\n",
    "Let us now try to simulate these curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_with_err(x, data, **kwargs):\n",
    "    mu, std = data.mean(1), data.std(1)\n",
    "    lines = plt.plot(x, mu, '-', **kwargs)\n",
    "    plt.fill_between(x, mu - std, mu + std, edgecolor='none',\n",
    "                     facecolor=lines[0].get_color(), alpha=0.2)\n",
    "    \n",
    "def rms_error(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return np.sqrt(np.mean((y - y_pred) ** 2))\n",
    "\n",
    "def plot_learning_curve(degree=3):\n",
    "    train_sizes = np.linspace(0.05, 1, 20)\n",
    "    N_train, val_train, val_test = learning_curve(PolynomialRegression(degree),\n",
    "                                                  X, y, train_sizes, cv=5,\n",
    "                                                  scoring=rms_error)\n",
    "    plot_with_err(N_train, val_train, label='training scores')\n",
    "    plot_with_err(N_train, val_test, label='validation scores')\n",
    "    plt.xlabel('Training Set Size'); plt.ylabel('rms error')\n",
    "    plt.ylim(0, 3)\n",
    "    plt.xlim(5, 80)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "degree = 1\n",
    "X, y = make_data(200, error=1.0, random_seed=degree)\n",
    "plot_learning_curve(degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows a typical learning curve: for very few training points, there is a large separation between the training and test error. As the data set size increases, the training and testing errors converge and plateau out. \n",
    "\n",
    "t is easy to see that, in this plot, if you'd like to reduce the MSE down to the nominal value of 1.0 (which is the inherient noise we added), then adding more samples will never get you there.\n",
    "\n",
    "What about now for the other extreme of high variance and low bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "degree = 9\n",
    "X, y = make_data(200, error=1.0, random_seed=degree)\n",
    "plot_learning_curve(degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that by adding more model complexity, we've managed to lower the level of convergence to an rms error of 1.0! But the convergence happens for arge amounts of training data.\n",
    "\n",
    "So we see that:\n",
    "\n",
    "* you can cause the lines to converge by adding more points or by simplifying the model\n",
    "* you can bring the convergence error down only by increasing the complexity of the model\n",
    "\n",
    "Thus these curves can give you hints about how you might improve a sub-optimal model. If the curves are already close together, you need more model complexity. If the curves are far apart, you might also improve the model by adding more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wage Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wage = pd.read_csv(\"../data/Wage.csv\", index_col='id')\n",
    "wage.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
    "\n",
    "age_mean = wage.groupby(by='age').wage.mean()\n",
    "axes[0].plot(age_mean.index, age_mean.values, '-', color='b', lw=3, label='Mean')\n",
    "axes[0].scatter(wage.age, wage.wage, color='#cccccc')\n",
    "axes[0].set_xlabel('Age')\n",
    "axes[0].set_ylabel('Wage')\n",
    "remove_border(axes[0])\n",
    "\n",
    "year_mean = wage.groupby(by='year').wage.mean()\n",
    "axes[1].plot(year_mean.index, year_mean.values, '-', color='b', lw=3, label='Mean')\n",
    "axes[1].scatter(wage.year, wage.wage, color='#cccccc')\n",
    "axes[1].set_xlabel('Year')\n",
    "axes[1].set_ylabel('Wage')\n",
    "remove_border(axes[1])\n",
    "\n",
    "\n",
    "year_mean = wage.groupby(by='year').wage.mean()\n",
    "axes[1].plot(year_mean.index, year_mean.values, '-', color='b', lw=3, label='Mean')\n",
    "axes[1].scatter(wage.year, wage.wage, color='#cccccc')\n",
    "axes[1].set_xlabel('Year')\n",
    "axes[1].set_ylabel('Wage')\n",
    "remove_border(axes[1])\n",
    "\n",
    "wage.boxplot('wage', by='education')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sales Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/Advertising.csv', index_col='id')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(data[['TV']], data.Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tv = np.arange(0,300)\n",
    "plt.plot( regr.coef_*tv + regr.intercept_, color='b')\n",
    "\n",
    "plt.scatter(data.TV, data.Sales, color='k')\n",
    "plt.xlabel('TV')\n",
    "plt.ylabel('Sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sse = np.sum((regr.predict(data[['TV']]) - data.Sales) ** 2, axis=0) / float(data[['TV']].shape[0] - data[['TV']].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "se = np.array([\n",
    "            np.sqrt(np.diagonal(sse[i] * np.linalg.inv(np.dot(data[['TV']].T, data[['TV']]))))\n",
    "                                                    for i in range(1,1)\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum((regr.predict(data[['TV']]) - data.Sales) ** 2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " y, X = dmatrices('Sales ~ TV + Radio + Newspaper', data=df, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " mod = sm.OLS(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " res = mod.fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print res.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "corr = {}\n",
    "corr['pearson'], _ = stats.pearsonr(data.Radio,data.Sales)\n",
    "corr['spearman'], _ = stats.spearmanr(data.Radio,data.Sales)\n",
    "corr['kendall'], _ = stats.kendalltau(data.Radio,data.Sales)\n",
    "\n",
    "print(corr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
